# Planificación del proyecto {#sec:plan}

A la hora de gestionar y planificar un proyecto existen dos tipos de enfoque, el predictivo y el adaptativo. El enfoque predictivo se utiliza cuando se tiene claro cómo va a ser el proyecto y se conocen las variables y resultados del mismo, mientras que el enfoque adaptativo es más flexible y permite modificar el alcance del proyecto conforme a las necesidades que van surgiendo a lo largo del desarrollo del propio proyecto. Este segundo enfoque conduce a una mayor calidad y productividad aumentando el compromiso del equipo [@enfoquesagiles]. 

En nuestro caso, hemos seguido un enfoque adaptativo ya que nuestro proyecto requiere flexibilidad y velocidad. Para ello, hemos seguido una metodología *agile* para desarrollar nuestro proyecto. Esta metodología consiste en trocear el proyecto en pequeñas partes que se tienen que ir completando en cortos periodos de tiempo. Siguiendo esta idea, hemos dividido las tareas semanalmente, de tal manera que en cada reunión definimos las tareas a realizar la próxima semana.

Adicionalmente, hemos empleado herramientas ágiles como el tablero *Kanban*, el cual nos ayuda a gestionar el proyecto de una manera más visual, viendo en qué estado se encuentra cada tarea que hemos definido. Para ello hemos utilizado la herramienta *Notion* [@notion] como podemos ver en la figura \ref{fig:tabnotion}, la cual muestra un ejemplo de cómo hemos ido organizando las distintas tareas a lo largo de este proyecto. *Notion* también nos permite crear un tablero distinguiendo el estado actual de las tareas en "sin empezar", "en curso" o "terminadas" y también ofrece la posibilidad de asignar cada tarea a uno o varios miembros del equipo que serán los encargados de completarlas.

![Tablero de las tareas en Notion](img/tabnotion.png){width=50% #fig:tabnotion}

Nuestro proyecto ha seguido un ciclo de vida iterativo e incremental, de tal manera que en cada iteración se ha revisado y mejorado el producto, el cual ha sido desarrollado por partes que se han ido integrando para construir el producto final.

A continuación, describiremos los puntos más importantes que hemos seguido en cuanto a la planificación del proyecto, en aspectos como el sistema de control de versiones utilizado, la gestión de las pruebas y los sistemas de despliegue de versiones implementados.  

## Gestión de configuración del Software

### Sistema de control de versiones

Para una correcta gestión y desarrollo de cualquier proyecto *software* un sistema de control de versiones es esencial e imprescindible para un equipo de desarrollo. Para nuestro trabajo hemos utilizado el ampliamente extendido *Git*. Este sistema nos permite sincronizar las distintas versiones garantizando la gestión de conflictos  entre los cambios realizados por el equipo de desarrollo. También guarda los datos de las distintas versiones para que sean recuperables en cualquier momento si fuese necesario. Para el alojamiento del repositorio del código hemos utilizado la plataforma *Github*. 

Además hemos establecido un procedimiento de gestión de ramas en nuestro repositorio, con el fin de tener controladas las distintas funcionalidades desarrolladas. El repositorio contiene 2 ramas principales, la rama "dev" que es  la que utilizamos diariamente para desarrollar nuestro producto, y que es donde se encuentra todo el código que está siendo desarrollado en el momento y que por lo tanto no está acabado. Por otro lado rama "main", que es la principal y la que contiene las funcionalidades terminadas y probadas. Esta rama "main" contiene la versión más actualizada de la aplicación. Cuando se ha terminado de desarrollar una versión y esta está probada en la rama "dev", se procede a hacer *merge* hacia la rama "main".

Por último, tenemos ramas auxiliares que utilizamos para desarrollar funcionalidades más específicas, de tal manera que si los cambios realizados hacen que otras partes de la aplicación puedan no funcionar, no afecte al resto y se pueda realizar un *backup* de manera sencilla. Un ejemplo de estas últimas pueden ser las ramas llamadas *OAuth2.0* o *modoOfline* cuyo nombre hace referencia al desarrollo de dicha funcionalidad que se decidió hacer por separado a las ramas principales. Una vez implementadas dichas funcionalidades, estos cambios pasan a la rama dev y posteriormente a main.

### Entornos de desarrollo e Integración

*Amazon Web Services* (*AWS*) ha sido una parte clave para nuestro proyecto. Este famoso proveedor de servicios en la nube dispone de gran cantidad de recursos de computación. Para nuestro proyecto hemos utilizado el servicio *EC2* bajo la prueba gratuita de este mismo. Este servicio permite crear instancias de máquinas en los servidores de *AWS* donde se puede ejecutar cualquier tipo de aplicación o proceso. La prueba gratuita ofrece la posibilidad de crear y tener encendida una de estas instancias, sin ningún coste durante un año siempre y cuando no se sobrepasen ciertos límites de uso, que de darse el caso se cobra las tasas estándar. Sin embargo, para el desarrollo del trabajo no hemos llegado ni por asomo a superarlos. Estos límites son 750 horas de uso de instancias mensuales, 35GB de uso de almacenamiento y 100GB de tráfico de red mensuales.

Para el desarrollo del trabajo creamos una instancia con un sistema operativo *Linux* que en este caso era una distribución de *Amazon* llamada *Amazon Linux*, esta distribución está diseñada para ser fácilmente configurada para los diversos servicios de *AWS* aunque también es posible usar cualquier otro tipo de distribuciones u otros sistemas operativos. El principal uso que hemos hecho de esta instancia ha sido la ejecución de nuestro *backend* en la nube, lo cual nos ha facilitado bastante el proceso de desarrollo ya que hemos podido ejecutar nuestra aplicación en un entorno de servidor y realizar las correspondientes integraciones con el *frontend*. Además tener el proyecto siendo ejecutado en la nube nos ha permitido que todos los miembros del equipo pudieran probar con facilidad los cambios realizados por los demás así como compartir el contexto de datos de la aplicación, lo que ha facilitado las pruebas.

En la instancia previamente mencionada hemos instalado el sistema de gestión de contenedores *Docker*, que es el sistema con el que se ejecuta completamente el *backend*. Mediante la herramienta de dicho sistema llamada *Docker-compose* podemos ejecutar varios contenedores y que éstos sean gestionados de manera conjunta por *Docker*. Para ello definimos en un fichero *.yaml* el conjunto de contenedores que serán ejecutados dentro del mismo entorno así como la configuración de cada uno. Esta configuración coincide con la modelada en la sección \ref{sec:arqui}. En nuestro caso tenemos 2 contenedores, uno formado a partir de una imagen de *Node.js* donde se ejecuta la *API Rest* y otro donde se ejecuta la base de datos, el cual está generado a partir de una imagen de *Postgresql*. La principal ventaja de esta herramienta es la posibilidad de definir todos los servicios a ejecutar dentro de un solo fichero con el fin de luego desplegar o ejecutar en la máquina todos ellos con un solo comando en vez de tener que gestionar por separado todos estos servicios. Además *Docker* crea un red interna para los contenedores de manera que puedan conectarse entre sí, si la situación lo requiere, como por ejemplo en nuestro caso, donde tenemos por separado un contenedor con la base de datos y otro con la *API REST*.

#### Sistema de despliegue

![Diagrama del sistema de despliegue](img/pipelinedespliege.png){width=100% #fig:diagramadespliegue}

Uno de los aspectos que más nos han ayudado a la hora de desarrollar nueva funcionalidad y gestionar la calidad de esta ha sido la puesta en marcha de un sistema de despliegue de versiones en el entorno de la nube mencionado anteriormente. Este sistema consiste en un *script* de *bash* que hemos escrito para poder realizar con agilidad despliegues en el entorno y facilitar las pruebas de integración con el *frontend*, así como la puesta en producción de funcionalidad. 

El *script* es lanzado cuando queremos desplegar una nueva versión para probar los cambios desarrollados en local en el entorno del servidor. El proceso que sigue el *script* puede verse modelado en la figura \ref{fig:diagramadespliegue} donde se observa el flujo que sigue nuestro código cuando realizamos el despliegue. En primer lugar lanzamos el *script* precedido por un *commit* que hayamos realizado y que queramos probar. Después se procede a clonar el código de nuestro repositorio en la máquina. A continuación nos pregunta qué rama queremos desplegar; casi siempre suele ser la rama "dev" ya que es donde se desarrolla la funcionalidad principal, aunque en ocasiones utilizamos las ramas auxiliares que hemos comentado en el apartado anterior. Tras seleccionar la rama, el *script* inicia el proceso de despliegue de los contenedores, ejecutando la herramienta *Docker-compose*. El *script* primero detiene los contenedores en ejecución y a continuación inicia el *build* y el *run* de los nuevos, es decir prepara las imágenes de los contenedores con los cambios descargados previamente del repositorio para luego iniciar su ejecución. Tras este último paso los cambios realizados sobre el repositorio se encuentran ya en el entorno.

Cada vez que se realiza un despliegue comenzamos con las pruebas en entorno donde volvemos a comprobar que los cambios también funcionan en este. Para ello seguimos el mismo procedimiento que en local pero apuntando a la *IP* del servidor. Para realizar está acción utilizamos la herramienta *Postman* que permite lanzar peticiones a nuestra *API* y ejecutar sus operaciones. Si observamos que el resultado de la ejecución de las llamadas al servidor no es correcto y detectamos algún fallo procedemos a mirar los logs del contenedor que ejecuta la *API*. Para este aspecto hemos incluido en el código métodos de *logging* y trazado para facilitar la detección de errores así como para depurar el funcionamiento del código. Entre estos métodos disponemos de un sistema que imprime todas las *queries* ejecutadas y el resultado de éstas en cuanto a datos devueltos o tiempo de respuesta entre otros. También disponemos de la librería de *Node.js Morgan* [@morgan] la cual imprime en el *log* todas las *request* que recibe la *API* así como la información sobre éstas como método *HTTP*, código de respuesta o tiempo de respuesta entre otros. Si detectamos algún error procedemos a replicarlo en local, solucionarlo e iniciar de nuevo el proceso de despliegue.
